
@[toc]

#  Authors and Publishment

* Michael Postmensil / Bell Laboratories
* Indranil Chakravarty / Schlumberger-Doll Research

SIGGRAPH '83: Proceedings of the 10th annual conference on Computer graphics and interactive techniquesJuly 1983 Pages 389–399https://doi.org/10.1145/800059.801169


# Categories

Computer Graphics

# 0. Abstract

This paper describes a procedure for modeling motion blur in computer-generated images. Motion blur in photography or cinematography is caused by the motion of objects during the finite exposure time the camera shutter remains open to record the image on film. In computer graphics, the simulations of motion blur is useful both in animated sequences where the blurring trends to remove temporal aliasing effects and in static images where it portrays the illusion of speed or movement among the objects in the scene.

> 本文描述了在计算机生成的图像中对运动模糊进行建模的过程。 摄影或电影摄影中的运动模糊是由在相机快门保持打开以将图像记录在胶片上的有限曝光时间内物体的运动引起的。 在计算机图形学中，运动模糊的模拟在动画中很有用，在动画中模糊趋势消除时间混叠效果，在静态图像中它描绘了场景中物体之间的速度或运动的错觉。 

The camera model developed for simulating motion blur is described in terms of a generalized image-formation equation. This equation describes the relationship between the object and corresponding image points in terms of the optical system-transfer function. The use of the optical system-transfer function simplifies the description of time-dependent variations of object motion that may occur during the exposure time of a camera. This approach allows us to characterize the motion of objects by a set of system-transfer functions which are derived from the path and velocity of objects in the scene and the exposure time of a camera.

> 为模拟运动模糊而开发的相机模型是根据广义图像形成方程描述的。 该方程根据光学系统传递函数描述了物体与相应像点之间的关系。 光学系统传递函数的使用简化了对相机曝光期间可能发生的物体运动随时间变化的描述。 这种方法允许我们通过一组系统传递函数来表征对象的运动，这些系统传递函数源自场景中对象的路径和速度以及相机的曝光时间。 

# 1. Introduction

The generation of computer-synthesized images with a high degree of realism has been the topic of much current research. The increase in realism in recent years can be attributed mainly to improved shading techniques and to more versatile 3D object modeling techniques that can represent complex objects with great detail. The objective of this paper is to report an image synthesis technique which incorporates the optical effects of a camera in imaging a scene. These optical effects of a camera add another dimension of realism in computer generated images. In this paper we attempt to model **motion blur**,  an effect caused by the movement of objects during the exposure time of the camera, and used often to portray to the viewer the illusion of the motion of objects.

> 生成具有高度真实感的计算机合成图像一直是当前的研究主题。近年来，我们通过3D技术建模来获得这一真实感，这些技术可以非常详实地表现复杂对象。而在本文中所提到的，是一种图像合成技术，该技术结合了相机对场景成像时的光学效果。这些光学效果在计算机生成的图像中增加了另一个维度的真实感。在本文中，我们尝试对**运动模糊**进行建模，这是一种由相机曝光期间，物体运动导致的效果，通常用于描绘物体运动时某种视觉错觉。 

In a previous paper [6,7] the authors developed a technique for modeling the effects of a lens and aperture in a camera model for computer-synthesized images. This paper is both an extension and a generalization of the previous paper to incorporate the effects of the camera shutter. In addition, this paper presents the image-generation process in terms of a cascaded optical, system-transfer function which specifies the relationship between object and image points. This formalism allows us to express easily the time-dependent variations of an object's position and provides a more comprehensive approach to synthesizing the effects of motion blur and other camera effects.

> 在之前的一篇论文[6, 7]中，作者开发了一种技术，用于在合成图像的相机模型里，对镜头和光圈的效果进行了建模。 这篇论文既是对前一篇论文的扩展和概括，又包含了相机快门对成像的影响。此外，本文根据级联光学系统传递函数，介绍了图像生成的过程，该函数关联了物体和像素点之间的关系。这种数学形式使我们能够轻松表达物体位置随时间的变化关系，并提供一种更全面的方法来合成运动模糊和其他相机效果。 

> **<批注>**
> 像素点是数字图像技术普及后的产物，在此以前的胶片时代是没有像素点这个概念的。因为文章成文时间较早，作者写作的年代有图像点这种概念，但为了和现在进行联系，我会在文中把所有 image points 统一翻译成像素点。

The appearance of motion blur in images can occur due to a number of reasons. The primary cause of this blurring is due to the movement of an object's position in the scene during the exposure time of the camera. By exposure time we mean the time during which the camera shutter remains open and the film acts as an integrating medium to accumulate the total radiant energy of the objects in the scene. 

> 图像中出现运动模糊的原因有很多；这种模糊的主要原因是在相机曝光期间，物体、相机与场景中的相对位置的移动。曝光时间是指相机快门保持打开状态且胶片充当积分介质，累积场景中物体的总辐射能量的时间。

There are two principal reasons for motion blur:

> 导致运动模糊主要有两个原因： 

1. Movements of Objects - The motion of objects in the scene is the most common cause for image blurring. The motion of objects can be classified into three categories: motion of the camera and a static scene, motion of objects with a static camera, and finally the simultaneous motion of both camera and objects in the scene.

> 1. 物体的运动 - 场景中物体的运动是图像模糊的最常见原因。 物体的运动可以分为三类：1）静态的场景和运动的相机；2）静态的相机和运动的物体，3）最后是相机和场景中物体的同时运动。 

2. Movement of the Shutter - Film is exposed in a camera by the movement of the shutter across the film plane. The finite opening and closing time of the shutter, the direction of movement of the shutter as well as changes in the shape of the aperture caused by the movement of the shutter may all modify the appearance of motion blur in the image [13]. In this paper we will not be concerned with modeling the blur arising solely from the functioning of the camera shutter.

> 2. 快门的运动- 快门在有限的开闭时间内，快门的运动方向引起的光圈形状变化都可能改变图像中运动模糊的外观[13]。在本文中，我们将不涉及相机快门功能引起的模糊。 

The problem of characterizing the degradation caused by an optical system has been the topic of extensive research in image processing [1]. The removal of camera degradation to recover the original image based on some a priori knowledge of the degradation phenomenon is called **image restoration**. In synthesizing motion blur the problem is almost inversed, that is, the objective is to generate an appropriate degradation function given an idealized description of the scene. Although one can draw upon the techniques developed for estimating the optical system-transfer function from a degraded image, the synthesis of an optical system-transfer function from a scene description must take into account the individual motion of objects in the scene, the camera path, the occlusion relationships that may vary between the objects during the exposure time, and any optical effects included as part of the camera model. 

> 由光学系统引起的图像退化问题一直是图像处理中广泛的课题[1]。基于退化现象的一些先验知识去除相机退化以恢复原始图像的过程称为**图像恢复**。在合成运动模糊时，问题几乎是相反的，也就是说，在给定场景的理想化描述的情况下生成适当的退化函数。虽然可以直接利用已有的光学传递函数（从退化图像上获得的评估模型），但是从必须考虑到场景中的个体运动、相机的运动路径、以及在曝光时间内物体之间的遮蔽关系，甚至任何可以作为相机模型参数之一的光学效果。

The generation of motion blur in computer-synthesized images, as described in this paper, consists of two stages: 1) a hidden-surface program generates intensity sample points of an instantaneous image identifying points which are in motion and giving the image path of the projected motion; and 2) a post-processor which blurs points by convolving them with the optical system-transfer functions derived from the image path and merges them with the stationary points into a final raster image.

> 如本文所述，计算机合成运动模糊包括两个阶段：1）瞬时生成图像的采样点，识别运动中的点并计算运动投射路径；2) 从图像路径获得的光学系统传递函数与运动点作卷积，与静止点合成最终的光栅图像。 

A ray-tracing program with a recursive shader [15] generates image point samples, keeping intensity contributions due to surface reflections, transparencies and shadows separate. This allows moving objects reflected in mirrors, transmitted through transparent surfaces, and the shadows of such objects to be blurred. For proper merger of moving objects with stationary objects, intensity samples of the stationary surfaces, hiding or hidden by the moving surfaces, are also computed.

> 带有递归着色器的光线追踪程序[15]生成像素点样本，将反射、透明度和阴影造成的强度变化分离。这允许移动物体反射在镜子里，或透过透明物体，以及它们被模糊的阴影。为了适当地合并移动物体和静止物体，还需要计算物体之间的遮罩关系。

The sample points which contain intensity reflected from moving objects are convolved with an optical system-transfer function, derived from the path and velocity of the motion, and the exposure time. The blurred moving objects and the stationary objects are then merged in a time-and-depth buffer into the final image. In this buffer the visibility of a surface point is determined by its depth, and its intensity is modified by the amount of exposure time it remains visible. A hidden-surface program which processes projected surfaces in a back-to-front order [5] can directly convolve each moving object with its optical system-transfer function as it is stored into the output image.

> 采样点（包含物体运动时光照辐射强度）与光学系统传递函数进行卷积，该函数源自运动的路径和速度以及曝光时间。 模糊的运动物体和静止物体在时间和深度缓冲区中合并成最终图像。 在这个缓冲区中，一个表面点的可见性由它的深度决定，它的强度由曝光时间量来调整。我们依照从后到前的顺序依次处理物体表面的投影，并让每个物体与其对应的光照系统传递函数进行卷积，最终输出到图像中[5]。


> **「批注」**
> 在你阅读第二节前，整个第二节内容介绍的就是一般成像过程及原理（以当前主流的计算机图形学的观点，即从三维场景投影到二维平面，再通过类似于光栅成像的方式得到最终的二维图像），这篇论文里真正关于运动模糊的算法，集中在第三节。有需要的可以直接看完第一节后，跳转到第三节。完成阅读后再返回第二节，补充一些必要的背景知识。

# 2. Image Formation Model

The camera model which underlies the image-formation process, as modeled here, consists of two stages. First, a 3D scene is projected by a geometric transformation into a 2D **image-irradiance plane**. The image-irradiance plane is then further transformed by the optical system-transfer function, also called a **point-spread function (PSF)**, into an actual raster image called the image-output plane. The image-output plane simulates a film by acting as a medium for accumulating the radiant energy of objects during the exposure time.

> 作为图像形成过程的相机模型，如这里所建模的，由两个阶段组成。首先，3D场景通过几何变换投影到2D的 **图像辐照度平面**。 然后，图像辐照度平面通过光学系统传递函数（也称为 **点扩散函数 (PSF)**）进一步转换为实际光栅图像，称为图像输出平面。图像输出平面通过充当积分介质在曝光时间内积累物体的辐射能来模拟胶片。

> **<批注>**
> 这里的 **图像辐射照度平面（image-irradiance plane）** 通常是我们图形、图像学里常提到的投影平面。而 **图像输出平面** 也就是光栅平面。三维场景以及三维物体投影到二维平面时，需要做透视变换，如果不考虑光照量的情况时，只会在二维平面上表现近大远小的关系，但是如果加入光学系统后，就会由于透视远近，远处的物体因为光线传递的衰减而在成像平面（光栅平面）呈现模糊的特点，这一点不需要专门的学科知识背景，如果你有比较好的观景台，眺望一下远方就能很快明白了。

The 3D scene is defined in a homogeneous coordinate system $O(x, y, z, w)$ and contains a set of 3D objects represented by $e_i(x, y, z, w)$, $i=1, 2, \cdots, n$ as shown in Figure 1. This representation contains both geometrical and optical properties of the objects. This is refered to as the **object-space** coordinate system. A geometrical transformation function $q(x', y', e_i(x, y, z, w))$ transforms object descriptions from $O(x, y, z, w)$ to $O'(x', y')$ (image-irradiance plane) eliminating hidden surfaces of objects and generating the radiant intensity for each visible surface point:

> 3D场景定义在坐标系 $O(x, y, z, w)$ 中，它包含一组由 $e_i(x, y, z, w)$, $i=1, 2 \cdots, n$ 表示的3D对象, 如图1所示。

此表示包含对象的几何和光学属性。 这称为**对象空间**坐标系。 几何变换函数 $q(x', y', e_i(x, y, z, w))$ 将对象描述从 $O(x, y, z, w)$ 转换为 $O'(x', y ')$ (image-irradiance plane) 消除物体的隐藏表面并为每个可见表面点生成辐射强度： 

**Eq. 2-1**

$$
f(x', y') = q(x', y': e(x, y, z, w))
$$

**Fig. 1**

![在这里插入图片描述](https://img-blog.csdnimg.cn/cf19836191f94d0380bc3727edb9b5a7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)



A discrete formulation of the image-irradiance function is equivalent to uniformly sampling the function $f(x', y')$ using a comb function (Figure 2) such that

> 图像辐照度函数的离散公式等效于使用梳状函数（图 2）对函数 $f(x', y')$ 进行均匀采样，使得 

**Eq. 2-2**

$$
f(i\triangle x', j\triangle y') = \sum_{i=0}^M \sum_{j=0}^N \delta(i\triangle x', j\triangle y') f(x', y')
$$

**Fig. 2**

![在这里插入图片描述](https://img-blog.csdnimg.cn/54445c062507453ea0c5c9b5cdffb0a7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)



where $\triangle x'$ and $\triangle y'$ are the sampling intervals in $x'$ and $y'$ directions, respectively. We will assume that the sampling rate is adequate so that we can reconstruct $f(x', y')$ from $f(i\triangle x', j\triangle y')$ by using a suitable interpolation function.  

> 其中 $\triangle x'$ 和 $\triangle y'$ 分别是 $x'$ 和 $y'$ 方向的采样间隔。 我们将假设采样率足够，以便我们可以通过使用合适的插值函数从 $f(i\triangle x', j\triangle y')$ 重建 $f(x', y')$。 

The transformation from the image-irradiance plane $O'(x', y')$ to the image-output plane $O''(x', y')$ (raster image) incorporates the degradation of the optical system and simulates the imaging medium. We denote this transformation as $h(x'', y'': x', y', f(x', y'))$, and thus we can express the raster image.

> 从图像辐照度平面 $O'(x', y')$ 到图像输出平面 $O''(x', y')$（光栅图像）的转换，此过程结合了光学系统的退化并模拟成像介质。因此，我们将这个变换表示为 $h(x'', y'': x', y', f(x', y'))$，这样我们就可以表达光栅图像了。

> **<批注>**
> 这个过程，现在更倾向表示为：
> $$
> g(x, y) = f(x, y) \odot h(x, y)
> $$
> 也就是原始图像，通过与退化函数计算卷积后，得到退化图像的过程。论文作者用这种比较繁琐的表示过程，主要是想反复强调从 「空间物体 $\rightarrow$ 投影平面 $\rightarrow$ 光栅平面」 的过程。

**Eq. 2-3**

$$
g(x'', y'') = h(x'', y'': x', y', f(x', y'))
$$

In order to quantify the transformation $h(x'', y'', x', y', f(x', y'))$ we will assume the following properties:

> 为了量化变换 $h(x'', y'', x', y', f(x', y'))$，我们将假设以下属性： 

1. The radiant intensity distrbution in both image-irradiance plane and the image-output plane is either positive or zero. This implies that the image-irradiance function (which is a measure of this energy distribution), and any transformations on the image-irradiance function may either conserve the energy or distribute it differently. Thus

> 图像辐照度平面和图像输出平面中的辐射强度分布为正值或零。 这意味着图像辐照度函数（它是这种能量分布的度量）以及对图像辐照度函数的任何变换都可以保存能量或以不同方式分布。 因此 

**Eq. 2-4**

$$
\begin{matrix}
f(x', y') \ge 0 & and & g(x'', y'') \ge 0
\end{matrix}$$


2. The radiant intensity distribution is additive in both the image-irradiance plane and the image-output plane. This superposition property implies that given two points $f_1(x', y')$ and $f_2(x', y')$ and their corresponding mapping $g_1(x'', y'')$ and $g_2(x'', y'')$ then 

> 辐射强度分布在图像辐照平面和图像输出平面中都是相加的。 这个叠加性质意味着给定两个点 $f_1(x', y')$ 和 $f_2(x', y')$ 以及它们对应的映射 $g_1(x'', y'')$ 和 $g_2(x '', y'')$  然后 

> **「批注」**
> 这里其实强调的就一句话，在原始图像的 $f(x, y)$ 只要信息存在，那么退化后的图像所对应的位置 $g(x, y)$ 上也一定存在信息。也就是「线性不变」的假设。

**Eq. 2-5**

$$
f_1(x', y') + f_2(x', y') = g_1(x'', y'') + g_2(x'', y'')
$$

Based on these two assumptions we may write the transformation from the image-irradiance plane $O'(x',y')$ to the output-image plane $O''(x'', y'')$ in the spatial domain by:

> 基于这两个假设，我们可以在空间上写出从图像辐照度平面 $O'(x',y')$ 到输出图像平面 $O''(x'', y'')$ 的变换域由： 

**Eq. 2-6**

$$
g(x'', y'') = \iint h(x'', y'': x', y', f(x', y')) dx' dy'
$$

> **「批注」**
> 本质上还是 $g(x, y) = f(x, y) \odot h(x, y)$，使用积分形式，表达的是对图像从第一个像素到最后一个像素做全局变换。也就是说，用退化函数 $h(x, y)$ 处理图像并最终输出退化图像。

where $h(x'', y'': x', y', f(x', y'))$ is the optical system transfer function (PSF) describing the energy distribution between points in the image-irradiance plane $O'$ and the output-image plane $O''$. This is the most general form for describing the image-formation process.

> 其中 $h(x'', y'': x', y', f(x', y'))$ 是光学系统传递函数 (PSF)，描述图像辐照度平面中点之间的能量分布 $O'$ 和输出图像平面 $O''$。 这是描述图像形成过程的最通用的形式。 

A number of simplifications can be made to the generalized image formation equation described above. If the additive components in the image-irradiance plane relate to the additive components in the image-output plane, then the system is said to be linear in which case equation (2-6) can be written in the more familiar form of

> 可以对上述广义图像形成方程进行多种简化。 如果图像辐照度平面中的相加分量与图像输出平面中的相加分量相关，则称系统是线性的，在这种情况下，方程 (2-6) 可以写成更熟悉的形式 

**Eq. 2-7**

$$
g(x'', y'') = \iint h(x'', y'': x', y') f(x', y') dx' dy'
$$

> **「批注」**
> 所以，你可以看到，这一步基本上可以看到已经是 $g(x, y) = h(x, y) \odot f(x, y)$ 的形式。

The description of the optical system-transfer function in terms of the all four coordinate variables $(x'', y'', x', y')$ reflects space-variance of the transfer function, that is, the transfer function is allowed to vary with position in the both the object space and image space. We define such a transfer function as a space-variant PSF (SVPSF). If we restrict the transfer function to be independent of position, that is, the PSF applies uniformly to all points in the object and image space then it is defined as space-invariant (SIPSF) which can be expressed as

> 用所有四个坐标变量 $(x'', y'', x', y')$ 来描述光学系统-传递函数反映了传递函数的空间方差，即传递函数为允许随对象空间和图像空间中的位置而变化。 我们将这样的传递函数定义为空间变体 PSF (SVPSF)。 如果我们限制传递函数与位置无关，即 PSF 统一应用于对象和图像空间中的所有点，那么它被定义为空间不变（SISF），可以表示为 

**Eq. 2-8**

$$
h(x'', y'': x', y') = h(x'' - x', y'' - y')
$$

In the space-invariant PSF case, the transformation from the image-irradiance plane $O'$ to the image-output plane $O''$ can be expressed with the convolution integral

> 在空间不变的 PSF 情况下，从图像辐照度平面 $O'$ 到图像输出平面 $O''$ 的变换可以用卷积积分表示 

**Eq. 2-9**

$$
g(x'', y'') = \iint h(x'' - x', y'' - y')f(x', y') dx' dy'
$$

We often denote the convolution operations int the spatial domain by the symbol * so that we may equivalently write equation (2-9) as $g(x'', y'') = h(x'', y'') * f(x', y')$. Finally in the discrete formulation $g(x'', y'')$ can be represented by the convolution summation

> 我们经常用符号 * 表示空间域中的卷积运算，这样我们可以等价地将方程（2-9）写成 $g(x'', y'') = h(x'', y'') * f( x', y')$。 最后在离散公式中 $g(x'', y'')$ 可以由卷积求和表示 

**Eq. 2-10**

$$
g(i\triangle x'', j\triangle y'') = \sum_{i=0}^{M} \sum_{j=0}^{N} h(i\triangle x'' - i \triangle x', j\triangle y'' - j\triangle y')f(i\triangle x', j\triangle y')
$$

The equivalent operation in the frequency domain can be written as the product of the Fourier transforms of the image-irradiance plane and the PSF:

> 频域中的等效操作可以写为图像-辐照度平面和 PSF 的傅立叶变换的乘积

**Eq. 2-11**

$$
G(u, v) = H(u, v)F(u, v)
$$

For incohenrent image formation systems, such as the ones we are trying to model, we only need to consider the squared magnitude of the PSF [4] in the convolution equations described above. The reason for this assumption is that the intensity (radiant energy) is dependent only on the amplitude and not the phase of a electro-magnetic field discribtuion.

> 对于非相关图像成形系统，例如我们试图建模的系统，我们只需要考虑上述卷积方程中 PSF [4] 的平方大小。这种假设的原因是强度（辐射能）仅取决于振幅而不取决于电磁场分布的相位。 

In many cases it is desirable to simplify the computation of convolution by factoring the 2D PSF into two 1D PSFs. This property is called the separability property of the PSF and can be expressed as follows for the space-invariant case as

> 在许多情况下，希望通过将 2D PSF 分解为两个 1D PSF 来简化卷积的计算。 这个特性被称为 PSF 的可分离特性，对于空间不变的情况可以表示如下 

**Eq. 2-12**
$$
h(x' - x'', y' - y'') = h_1(x'-x'') h_2(y'-y'')
$$
This implies that for an orthogonal coordinate space, the horizontal and vertical transformations can be performed sequentially and independently of each other.

> 这意味着对于正交坐标空间，水平和垂直变换可以顺序且彼此独立地执行。 

In many instances modeling the camera effects may results in serval PSFs cascaded together so that the overall transfer function achieves the desired effect. Given two PSFs $h_1(x'', y'': x', y')$ and $h_2(x'', y'': x', y')$ the overall transfer function $h_{12}(x'', y'': x', y')$ can be expressed as the convolution of the individual transfer functions $h_1(x'', y'': x', y') * h_2(x'', y'': x', y')$. Alternately, in the frequency domain this can be viewed as the product of the two individual transfer functions.

> 在许多情况下，对相机效果的建模可能会导致多个PSF级联在一起，以便整体传递函数达到所需的效果。给定两个 PSF $h_1(x'', y'': x', y')$ 和 $h_2(x'', y'': x', y')$ 整体传递函数 $h_{12}( x'', y'': x', y')$ 可以表示为各个传递函数 $h_1(x'', y'': x', y') * h_2(x'', y'': x', y')$。 或者，在频域中，这可以视为两个单独传递函数的乘积。 

> **「批注」**
> 这里其实可以表示成这样，对于一个复杂的退化函数 $h_s$ 它可以表示为多个简单的退化函数的卷积，即：
> 也就是说，如果对于原图像 $f(x, y)$，它通过 $h_s$ 退化成了 $g_s$，即：
> $$
> g_s = f(x, y) \odot h_s(x, y)
> $$
> 那么它也可以表示为一系列简单的退化函数依次和原图像 $f(x, y)$ 计算卷积的过程：
> $$
> g_s = [[[f \odot h_1] \odot h_2] \odot \cdots \odot h_n]
> $$
> 即：
> $$
> g_s = f(x, y) \odot h_1 \odot h_2 \cdots \odot h_n
> $$
> 同理，对于频域来说，则直接可以表示为
> $$
> G_s = F * H_1 * H_2 * \cdots * H_n
> $$


In summary the image formation model can be described by a two stage process as shown in Figure 3. The first is a geometrical transformation which projects the object space onto an image-irradiance plane resolving the hidden surfaces and calculating the radiant intensity for each discrete visible point. We call this process the scene imaging system. An optical system-transfer function (PSF) is then used to transform the image-irradiance plane to the image-output plane. The PSF describes the relationship of the energy distributions between the image-irradiance plane and image-output planes incorporating the effects of the lens, aperture, and shutter. The output-image plane thus acts as an integrating medium accumulating the total radiant energy during the exposure time of the camera.

> 总之，图像形成模型可以通过如图 3 所示的两阶段过程来描述。第一个是几何变换，它将物体空间投影到图像-辐照度平面上，解析隐藏表面并计算每个离散可见光的辐射强度, 我们称这个过程为场景成像系统。然后使用光学系统传递函数 (PSF) 将图像辐照平面转换为图像输出平面。 PSF 描述了图像辐照度平面和图像输出平面之间的能量分布关系，包括镜头、光圈和快门的影响。 因此，输出图像平面充当积分介质，在相机的曝光时间内累积总辐射能量。 

> **「批注」**
> 其实也就是从三维场景投影到二维平面，再通过二维平面进行渲染得到最终输出的过程。

**Fig. 3**

![在这里插入图片描述](https://img-blog.csdnimg.cn/5b945f1633234f6f92ce6b4894ce8aac.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

# 3. Effects of Object Motion and Camera Shutter

## 3.1. Point-Spread Function of Object Motion

The problem of blurring the output image function $g(x'', y'')$ due to object motion during the exposure time [1, 11, 12, 13] is described in this section. Let the path of the object motion be described in the 3D  object coordinate system $O(x, y, z, w)$ as a parametric function of time:

> 本节描述了在曝光时间 [1, 11, 12, 13] 期间由于物体运动而使输出图像函数 $g(x'', y'')$ 模糊的问题。 让物体运动的路径在 3D 物体坐标系 $O(x, y, z, w)$ 中描述为时间的参数函数： 

**Eq. 3-1**

$$
r(t) = [x(t), y(t), z(t), w(t)]
$$

which is projected into the 2D object coordinate system $O'(x', y')$ as:

> 投影到 2D 对象坐标系 $O'(x', y')$ 为： 

**Eq. 3-2**

$$
r'(t) = [x'(t), y'(t)]
$$

by the geometrical transformation $q(x', y', : x, y, z, w)$ as in equation (2-1):

> 根据几何传递函数 $q(x', y', : x, y, z, w)$ 有下面的公式

**Eq. 3-3**

$$
r'(t) = q(x', y': r(t))
$$

We assume that all the projected points in $f(x', y')$ of an object are moving along a single projected path $r'(t)$, that is, $r(t)$ is projected into a space-invariant $r'(t)$ in $O'(x', y')$. By this we mean that the blurring is applied uniformly to all points along the projected path of motion.

> 我们假设一个物体 $f(x', y')$ 中的所有投影点都沿着单个投影路径 $r'(t)$ 移动，即 $r(t)$ 被投影到一个空间 $O'(x', y')$ 中不变的 $r'(t)$。 我们的意思是将模糊均匀应用于沿投影运动路径的所有点。 

Suppose that the motion of the object can be stopped at some instant t, and this instantaneous image can be expressed as $g(x'', y'', t)$. Then the recorded image-output function $g(x'', y'')$ during the fixed exposure time interval [0, T] is:

> 假设物体的运动可以在某个时刻 t 停止，这个瞬时图像可以表示为 $g(x'', y'', t)$。 那么固定曝光时间间隔[0, T]内记录的图像输出函数$g(x'', y'')$为： 

**Eq. 3-4**

$$
g(x'', y'') = \int_0^T g(x'', y'', t) dt
$$

> **「批注」**
> 这里最关键的就是上面这个公式，它表示了最终输出的退化图像 $g(x'', y'')$ 是由每时刻的退化图像 $g(x'', y'', t)$ 经时间 $T$ 的累积而来。换句话说，即
> $$g(x'', y'') = g_1(x'', y'') + g_2(x'', y'') + g_3(x'', y'') + \cdots g_t(x'', y'') $$

This integration is physically performed by the film or other recording medium. It can be described as the summation at image output point $(x'', y'')$ of the intensities of all object points that are mapped onto this image point during the exposure interval. Assuming that energy is conserved by the imaging system at any instant during the exposure, energy radiated by an area element $dx'$ $dy'$ of $O'(x', y')$ and collected by an area element $dx''$ $dy''$ of $O(x'', y'')$ is described by:

> 这种集成是由胶片或其他记录介质物理执行的。 它可以描述为在曝光间隔期间映射到该图像点的所有对象点的强度在图像输出点 $(x'', y'')$ 处的总和。 假设在曝光过程中的任何时刻，成像系统都保存了能量，则由 $O'(x', y')$ 的 $dx'$ $dy'$ 辐射并由 $O(x'', y'')$ 的 $dx''$ 和 $dy''$ 收集能量，其描述为：

**Eq. 3-5**

$$
g(x'', y'', t) dx'' dy'' = f(x', y') dx' dy'
$$

> **「批注」**
> 注意，这里并未考虑退化 $h$ 的影响，在没有 $h$ 的前提下，在某时刻 $t$ 由 $f(x, y)$ 到 $g(x, y)$ 的能量是线性并一致的。

at instant $t$. Substituting the path description (3-2) into (3-5) and combine it with (3-4) we obtain the recorded image function:

> 对于时刻 $t$ 来说，将路径描述（3-2）代入（3-5）并与（3-4）结合，得到记录图像函数： 

**Eq. 3-6**


$$
g(x'', y'') = \int_0^T f(x'(t), y'(t)) dt
$$


Given a description of the object motion $r'(t)$ (3-2) we convert the time integral of the moving object (3-6) into a positional integral over an equivalent stationary object. The elemental length $ds$ of path $r'(t)$ is given by:

> 给定物体运动 $r'(t)$ (3-2) 的描述，我们将移动物体 (3-6) 的时间积分转换为等效静止物体上的位置积分。 路径 $r'(t)$ 的微元 $ds$ 由下式给出： 

**Eq. 3-7**

$$
ds = \left [ \left [ \frac{dx'(t)}{dt} \right ]^2  + \left [ \frac{dy'(t)}{dt} \right ]^2 \right ]^{1/2}dt
$$

Therefore the time integral in equation (3-6) can be changed into line integral of the form:

> **「批注」**
> 我们可以把上面这个表达式改写为更直观的形式：
> $$
> ds = \sqrt{ (\frac{dx'(t)}{dt})^2 + (\frac{dy'(t)}{dt})^2 } \cdot dt
> $$
> 这里的 $dx(t)/dt$ 得到的是加速度，所以我们可以分别用 $a_x = dx(t) / dt$ 和 $a_y = dy(t) / dt$，所以上式可以进一步简化为
> $$
> ds = \sqrt{{a_x}^2 + {a_y}^2} \cdot dt \rightarrow dt = \frac{ds}{\sqrt{{a_x}^2 + {a_y}^2}}
> $$
> 由于加速度是标量，且 $a_x$ 和 $a_y$ 分别表示笛卡尔空间XOY平面的上X轴和Y轴的标量，所以我们可以使用勾股定理求解合成方向 $a_s$ 的加速度，关于这块的衍生拓展，可以看一些陀螺仪或者加速度姿态解算方面的扩展资料。

**Eq. 3-8**

$$g(x'', y'') = \int_{r'(0)}^{r'(T)} \frac{f(x', y')}{ \left [ \left [ \frac{dx'(t)}{dt} \right ]^2  + \left [ \frac{dy'(t)}{dt} \right ]^2 \right ]^{1/2}} ds$$

> **「批注」** 将上式改写为
> $$
> g(x'', y'') = \int_{r'(0)}^{r'(T)}    \frac{f(x', y')}{ \sqrt{{a_x}^2 + {a_y}^2} } ds  
> $$

which is a general expression for motion degradation with the linear space-invariant model of equation (2-9). The SIPSF can be identified in equation (3-8) as:

> 这是具有方程（2-9）的线性空间不变模型的运动退化的一般表达式。 SISF 可以在等式 (3-8) 中识别为： 

**Eq. 3-9**

$$h(x'', y'': x', y') = \left [ \left [ \frac{dx'(t)}{dt} \right ]^2 + \left [ \frac{dy'(t)}{dt} \right ]^2 \right ]^{- 1/2}$$

> **「批注」** 将上式改写为
> $$
> h(x'', y'' : x', y') = \sqrt{{a_x}^2 + {a_y}^2} 
> $$

where x'(t) and y'(t) are valid over the path of the object motion, that is 

> 其中 x'(t) 和 y'(t) 在物体运动路径上有效，即 

$$
x'(0) \leq x'(t) \leq x'(T) \\
y'(0) \leq y'(t) \leq y'(T)
$$

and h(x'', y'': x', y') = 0 elsewhere. The amplitude of the response is, therefore, inversely proportional to the velocity of the motion of an object point, i.e., as the object moves faster its image spreads over a greater image area with reduced intensity. Since the derived $h(x'', y'': x', y')$ is space invariant, the convolution in equation (2-10) with this PSF can be performed either in the spatial or the frequency domain.

> 在其他位置时，h(x'', y'': x', y') = 0。

> 因此，响应的幅度与物体点的运动速度成反比，即，当物体移动得更快时，它的图像以降低的强度扩展到更大的图像区域。 由于导出的 $h(x'', y'': x', y')$ 是空间不变的，方程（2-10）中与这个 PSF 的卷积可以在空间域或频域中执行。 

> **「批注」** 
> 结合3.8与3.9式，可以得到：
> $$
> g(x'', y'') = \int_{r'(0)}^{r'(T)}    \frac{f(x', y')}{ h(x'', y'': x', y') } ds  
> $$
> 结合上面的文字信息，也就是说只有在
> $$
> x'(0) \leq x'(t) \leq x'(T) \\
> y'(0) \leq y'(t) \leq y'(T)
> $$
> 上面的积分是有解的，而在其他时刻，积分无解（因为分母不能为0）。

Consider a simple example where $r'(t) = x_0(t)$ describes planar motion of the object in the x-direction. Using (3-6) we may write

> 考虑一个简单的例子，其中 $r'(t) = x_0(t)$ 描述了物体在 x 方向的平面运动。 使用（3-6）我们可以写 

**Eq. 3-10**

$$
g(x'', y'') = \int_0^T f(x'- x_0(t), y') dt
$$

and from the frequency-domain relationship in (2-11):

> 并从（2-11）中的频域关系： 

**Eq. 3-11**

$$G(u, v) = \iint \left [ \int_0^T f(x' - x_0(t), y')dt \right ] e^{-j 2 \pi (ux' + vy')} dx dy$$

> **「批注」** 
> 为了简化过程，只考虑物体以x轴或y轴方向移动了距离 $r(t)$，落在了 $x_0(t)$ 位置上，这个过程一共消耗时间为 $T$。
> 于是，根据上面的描述信息，我们可以通过公式 3.6 得到：
> **a1**
> $$
> g(x, y) = \int_0^T f(x - x_o(t), y) dt
> $$
> 之后，对退化后的图像 $g(x, y)$ 做傅立叶转化，可以得到
> **a2**
> $$
> G(u, v) = \iint g(x, y) e^{-j 2 \pi (ux + vy)} \cdot dx dy
> $$
> 把a1带入a2，有
> $$
> G(u, v) = \iint \left [  \int_0^T f(x-x_0(t),  y) \cdot dt \right ] \cdot e^{-j 2 \pi (ux + vy)}  \cdot dx dy
> $$

By reversing the order of integration and using the shifting property of Fourier transforms G(u, v) can be expressed as

> 通过颠倒积分顺序并利用傅立叶变换的移位性质，G(u, v) 可以表示为 

**Eq. 3-12**

$$G(u, v) = F(u, v) \int_0^T e^{-j 2 \pi (u x_0(t))} dt $$

> **「批注」** 
> 得到下式后，我们可以交换积分顺序
> $$
> G(u, v) = \iint \left [  \int_0^T f(x-x_0(t),  y) \cdot dt \right ] \cdot e^{-j 2 \pi (ux + vy)}  \cdot dx dy
> $$
> 使得上式变成
> $$
> G(u, v) =  \int_0^T \left[ \iint  f(x-x_0(t), y) \cdot e^{-j 2 \pi (ux + vy)} \cdot dx dy \right ] \cdot dt
> $$
> 现在我们可以从一维的情况直接扩展至二维，即目标在图片中任意方向运动，于是上式可以直接得到：
>$$
> G(u, v) =  \int_0^T \left[ \iint  f(x-x_0(t), y - y_0(t)) \cdot e^{-j 2 \pi (ux + vy)} \cdot dx dy \right ] \cdot dt
>$$
> 由于 $\iint  f(x-x_0(t), y - y_0(t)) \cdot e^{-j 2 \pi (ux + vy)} \cdot dx dy$ 可以改写为对与 $f(x - x_0(t), y - y_0(t))$ 的频域 $F(u, v)$ 的形式。注意，其中
> $$
> F(u, v) = \iint  f(x-x_0(t), y - y_0(t)) \cdot e^{-j 2 \pi [u(x - x_0(t)) + v(y - y_0(t))]}
> $$
> 所以，我们最终得到
> $$
> G(u, v) = F(u, v)  \int_0^T  e^{-j 2 \pi (ux_0(t) + vy_0(t))} dt
> $$

Let $x_0(t) = \frac{at}{T}$, and $0 \leq t \leq T$. Using (2-11) we identify

> 令 $x_0(t) = \frac{at}{T}$，并且 $0 \leq t \leq T$。 使用（2-11）我们确定 

> **「批注」** 
> 我们在前面的章节已经提到过，论文中加速度的表达为
> 
> * $a_x = dx(t) / dt$ 
> * $a_y = dy(t) / dt$
>
> 于是从这里可以得出，空间移动微元 $dx$ 和 $dy$ 它们在经过 $T$ 时间后，分别为
> * $dx = a_x * T$
> * $dy = a_y * T$
>
> 因此 $t/T$ 可以看作一个连续变化的比值，范围从[0, 100%]，当 $t=T$ 时，移动距离为 $a$。所以这也就是为什么：
> * $x_0(t) = a_x \cdot t/T$
> * $y_0(t) = a_y \cdot t/T$
> 
> 并令 $0 \leq t \leq T$。


**Eq. 3-13**

$$H(u) = \int_0^T e^{-j 2 \pi x_0(t)} dt$$

Substituting for $x_0(t)$, we obtain

> **「批注」** 
> 我确认过，论文在这里应该是小敲了个 $u$，正确的写法应该是：
> $$
> H(u) = \int_0^T e^{-j 2 \pi u x_0(t)} dt
> $$
> 另外，对于二维来说，它对应的退化函数为
> $$
> H(u, v) =  \int_0^T  e^{-j 2 \pi (ux_0(t) + vy_0(t))} dt
> $$

> 代入 $x_0(t)$，我们得到 

**Eq. 3-14**

$$H(u) = \int_0^T e^{-j 2 \pi \frac{u a t}{T}} dt = \frac{T}{\pi u a} \sin(\pi u a) e^{-j \pi u a}$$

> **「批注」** 
> 说实话，公式3-14是怎么推导出来的我确实没想明白，我尝试过几种不同的推导方式都无法得出这个结果，如果知道这步骤的朋友，能不能在留言告知一下？

Alternatively, you may directly obtain $h(x'')$ by substituting into (3-9)

> 或者，你可以通过代入（3-9）直接获得 $h(x'')$ 

> **「批注」** 
> 已知公式3.8
> $$
> g(x'', y'') = \int_{r'(0)}^{r'(T)}    \frac{f(x', y')}{ \sqrt{{a_x}^2 + {a_y}^2} } ds 
> $$
> 且已知公式3.9
> $$
> h^* (x, y) = \sqrt{{a_x}^2 + {a_y}^2}
> $$
> 所以可知对于上诉模型来说，其退化函数 $h(x, y)$ 应该为
>  $$
>  h(x, y) = \int_0^T \frac{1}{h^* (x, y)} = \frac{1}{ \sqrt{ a_x^2 + a_y^2 }} dt =  \frac{1}{ \sqrt{ a_x^2 + a_y^2 }} \int_0^T dt
>  $$
>  于是可得
>  $$
>  h(x, y) = \frac{T}{\sqrt{a_x^2 + a_y^2}}
>  $$
> 若只有一个方向的移动时，即变为：
> $$
> h(x) = \frac{T}{a_x}
> $$
> 其中，对于x和y分量来说，在[0, T] 时间内，由于
> * $x_0(t) = a_x \cdot t/T$
> * $y_0(t) = a_y \cdot t/T$
> 
> 所以，x 和 y 的各自取值范围都是 $[0, a]$。
 

**Eq. 3-15**

$$
\begin{matrix}
h(x'') = \frac{T}{a} & where & 0 \leq x'' \leq a
\end{matrix}
$$



It is easy to verify that (3-15) is indeed the inverse Fourier transform of (3-14). An example of uniform motion blur is shown in Figure 4. This simulates the motion of a camera viewing a static scene. Figure 4(a) shows the original natural image; the Fourier spectrum of this image is shown in Figure 4(b). This FFT was multiplied by the frequency-domain uniform blur function $x_0(t)$. The convolved image is shown in Figure 4(c) and the inverse FFT producing the blurred image is shown in Figure 4(d).

> 很容易验证（3-15）确实是（3-14）的逆傅里叶变换。 图 4 显示了均匀运动模糊的示例。这模拟了查看静态场景的相机的运动。 图 4(a) 显示了原始自然图像； 该图像的傅立叶频谱如图 4(b) 所示。 该 FFT 乘以频域均匀模糊函数 $x_0(t)$。 卷积后的图像如图 4( c) 所示，产生模糊图像的逆 FFT 如图 4(d) 所示。 

**Fig. 4**

![在这里插入图片描述](https://img-blog.csdnimg.cn/2ee28be98a6641ffb6b081c35f1e73b9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)


In the previous section we obtained a PSF due to object motion assuming instantaneous shutter opening at time $t=0$ and closing at time $t=T$. Most actual shutters, however, are mechanical devices which vary the shape of the aperture during their opening and closing times and therefore further modify the system PSF. Shack [13] derived the shutter PSF's for the two most common types of shutter.

> 在上一节中，我们假设在时间 $t=0$ 时快门瞬间打开并在时间 $t=T$ 时关闭，由于物体运动，我们获得了 PSF。 然而，大多数实际的百叶窗是机械装置，它们在打开和关闭时改变光圈的形状，因此进一步修改了系统 PSF。 Shack [13] 推导出了两种最常见的快门类型的快门 PSF。 

The focal-plane shutter is a narrow slit in a curtain which moves across the file frame, slightly in front of the film plane, usually in the $x''$ (horizontal) direction. The aperture remains open for the duration of the exposure. The exposure is controlled by the speed of the curtain motion and the width of the slit. The PSF for this shutter type is in the frequency domain [13]:

> 焦平面快门是帘幕中的一个狭缝，它穿过文件框，稍微位于胶片平面的前面，通常在 $x''$（水平）方向。 光圈在曝光期间保持打开状态。 曝光由帘幕运动的速度和狭缝的宽度控制。 这种快门类型的 PSF 在频域中 [13]： 

**Eq. 3-16**

$$
H(u, v) = \left \{ \begin{matrix} 
1 - \frac{|u|}{d} & 0 < |u| < d \\
0 & |u| > d
\end{matrix} \right.
$$

where $d$ is the ratio of the width of the curtain slit moving in the $x''$ direction and the radius of the aperture opening.

> 其中 $d$ 是沿 $x''$ 方向移动的帘缝宽度与孔径开口半径的比值。 

The between-the-lens shutter consists of a usually circular or star-shaped opening made of several blades, placed between lens elements, and similar in construction to the aperture diaphragm. The size of the shutter diaphragm increases as the shutter opens and decreases as the shutter closes. The aperture diaphragm of the lens remains open all the time. The PSF of this shutter type is substantially more complicated [13] than (3-10), and can be best approximated by a PSF of a circular aperture [6, 7] whose radius varies with time.

> 镜头间快门由一个通常为圆形或星形的开口组成，开口由多个叶片组成，位于镜头元件之间，结构与孔径光阑相似。 快门光圈的尺寸随着快门打开而增大，随着快门关闭而减小。 镜头的孔径光阑始终保持打开状态。 这种快门类型的 PSF [13] 比 (3-10) 复杂得多，并且可以最好地近似为半径随时间变化的圆形孔径 [6, 7] 的 PSF。 

The PSF's due to motion of objects and camera may be cascaded with the PSF due to the shutter into a single system-transfer function [Figure 5].

> 由于物体和相机的运动而产生的 PSF 可能与由于快门而产生的 PSF 级联成单个系统传递函数 [图 5]。 

# 4. Synthetic Image Generation

## 4.1. Hidden-Surface Elimination

A ray-tracing hidden-surface processor is used to compute the intensity point samples in $O'(x', y')$ from a description of a 3D scene and the camera geometry. The processor uses Whitted's recursive-illumination model [15] to compute intensity-point samples with the following shading equation:

> 光线追踪隐藏表面处理器用于根据 3D 场景和相机几何的描述计算 $O'(x', y')$ 中的强度点样本。 处理器使用 Whitted 的递归照明模型 [15] 使用以下着色方程计算强度点样本： 

**Eq. 4-1**

$$
f(i\triangle x', j\triangle y') = I_a + I_d + I_s + I_r + I_t
$$

where 

* $I_a =$ the ambient light intensity
* $I_b =$ the diffuse reflection
* $I_s =$ the specular reflection
* $I_r =$  the reflected light intensity
* $I_t =$ the transmitted light intensity

This equation can be recursively redefined for $I_r$, and $I_t$. The intensity change due to a shadow cast by an opaque object is:

> 这个方程可以递归地重新定义为 $I_r$ 和 $I_t$。 由不透明物体投射的阴影引起的强度变化为： 

**Eq. 4-2**

$$I_{shadow} = -I_d - I_s$$

The hidden-surface program generates a raster image with a pin-hole camera model, and optionally the separate image intensity samples $f(i\triangle x', j\triangle y')$ [6, 7]. Each sample consists of the following information obtained from a node of the shading tree at $O'(i\triangle x', j\triangle y')$

> 隐藏表面程序使用针孔相机模型生成光栅图像，并可选地生成单独的图像强度样本 $f(i\triangle x', j\triangle y')$ [6, 7]。 每个样本都包含以下从$O'(i\triangle x', j\triangle y')$处的着色树节点获得的信息 

1. the type of intensity information contained in the node: opaque, reflected, transmitted, hidden, or shadow.

> 节点中包含的强度信息类型：不透明、反射、透射、隐藏或阴影。 

2. the (i,j) coordinates of the sampled point.

> 采样点的 (i,j) 坐标。 

3. the red, green, and blue intensity values, $I_{red}$, $I_{green}$, and $I_{blue}$, contributed by the measured object point.

> 红色、绿色和蓝色强度值 $I_{red}$、$I_{green}$ 和 $I_{blue}$，由被测物点贡献。 

4. the z' depth (along the camera's optical axis) of the measured object point (not used for shadows),

> 被测物点（不用于阴影）的 z' 深度（沿相机的光轴）， 

5. the object identification number of the measured point (or object identification number of object casting shadow).

> 被测点的物体识别号（或物体投射阴影的物体识别号）。 

The list of sample of an image frame is then passed to a motion-blur processor together with a list of motion paths of the individual objects, time of the frame exposure $t_{frame}$, and the exposure duration $T_{frame}$. In an actual animation system, this information would be provided by an animation processor [2, 9, 14] which controls the motions of the objects and the camera. 

> 然后将图像帧的样本列表与单个对象的运动路径列表、帧曝光时间 $t_{frame}$ 和曝光持续时间 $T_{frame}$ 一起传递给运动模糊处理器 $. 在实际的动画系统中，此信息将由动画处理器 [2, 9, 14] 提供，该处理器控制对象和相机的运动。 

**Fig. 5**

![在这里插入图片描述](https://img-blog.csdnimg.cn/4a31bcc8165b43578a502addba755edf.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)


## 4.2 Addition of Motion Blur

Motion blur is generated by a processor shown in the block diagram in Figure 6. This processor separates sample points of a moving object with the same path $r'(t)$ into a raster image $f$. The motion blur PSF $h(x'',y'':xy)$ (equation 3-9) is computed from the object path $r'(t)$, the exposure time $I_{frame}$, and the exposure length $T_{frame}$ as a raster image $b$. The images $f$ and $h$ are then convolved into a blurred image $f*h$. This convolution can be performed either directly in the spatial domain, or optionally images $f$ and $h$ can be converted by FFT into $F$ and $H$, respectively, in the frequency domain, multiplied into $F \cdot H$, and then converted back into $f*h$ by an inverse FFT. Finally, all blurred images of the moving objects are merged with the image of the stationary objects into the output raster image.

> 运动模糊由图 6 框图中所示的处理器生成。该处理器将具有相同路径 $r'(t)$ 的移动对象的样本点分离为光栅图像 $f$。 运动模糊 PSF $h(x'',y'':xy)$（方程 3-9）是根据对象路径 $r'(t)$、曝光时间 $I_{frame}$ 和 曝光长度 $T_{frame}$ 作为光栅图像 $b$。 然后将图像 $f$ 和 $h$ 卷积为模糊图像 $f*h$。 这种卷积可以直接在空间域中执行，或者可选地，图像 $f$ 和 $h$ 可以通过 FFT 分别转换为 $F$ 和 $H$，在频域中，乘以 $F\cdot H$，然后通过逆 FFT 转换回 $f*h$。 最后，将运动物体的所有模糊图像与静止物体的图像合并成输出光栅图像。 

**Fig. 6**
![在这里插入图片描述](https://img-blog.csdnimg.cn/4cb2de18aa5d4d17a81929b56a9ef00a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)


To merge the stationary image with the blurred images of the moving objects, we need to compute in each blurred image the fraction of the exposure length $T_{frame}$ that the moving object overlaps each pixel. From this information we can also determine the amount of time $T_{frame}$ that each pixel in the stationary image is visible. This is accomplished by adding a fourth band (to the red, green and blue intensity bands) to each image $f$. This band contains the exposure length $T_{frame}$ in every pixel that the instantaneous image of the moving object overlaps and 0 elsewhere. This "time" band is convolved with the PSF $h$ exactly as the three image intensity bands. In image $f*h$ this band, therefore, contains the fraction of time $T_{frame}$ that the moving object overlaps each pixel. The hidden-surface processor also generates intensity samples of stationary objects hiding or hidden by the moving objects. (Intersections with hidden-surfaces are otherwise used by this program for processing solid objects [10].) The stationary image is an image of the scene without the moving objects, rather than an image with "black holes" in places where the moving objects are missing. The blurred images of the moving objects and the image of the station- ary objects are merged in a time-and-depth buffer. In this buffer the visibility of each pixel in the images being merged is determined by its depth, and its intensity by the length of time it remains visible. If a stationary surface is hiding a moving surface, the time exposure and therefore the intensity of the moving surface are reduced to 0. Otherwise, if one or more moving surfaces are hiding a sta- tionary surface, the intensity of the stationary surface is reduced by the amount of time it is invisible which is determined from the exposure time value computed in each blurred image $f*h$. If the sum of the computed exposure times of the moving surfaces exceeds $T_{frame}$ at a given pixel, then the intensity of the blurred moving surfaces is also appropriately reduced, and the stationary surface becomes, of course, completely invisible.

> 为了将静止图像与运动物体的模糊图像合并，我们需要在每个模糊图像中计算运动物体与每个像素重叠的曝光长度 $T_{frame}$ 的分数。根据这些信息，我们还可以确定静止图像中每个像素可见的时间量 $T_{frame}$。这是通过向每个图像 $f$ 添加第四个波段（到红色、绿色和蓝色强度波段）来实现的。该波段包含运动物体的瞬时图像重叠的每个像素中的曝光长度 $T_{frame}$ 和其他地方的 0。这个“时间”带与 PSF $h$ 卷积，与三个图像强度带完全一样。因此，在图像 $f*h$ 中，该带包含移动对象与每个像素重叠的时间部分 $T_{frame}$。隐藏面处理器还生成隐藏或被移动物体隐藏的静止物体的强度样本。 （该程序还使用与隐藏表面的交点来处理固体对象 [10]。）静止图像是没有移动对象的场景图像，而不是在移动对象所在位置带有“黑洞”的图像缺失。运动物体的模糊图像和静止物体的图像在时间和深度缓冲区中合并。在这个缓冲区中，被合并图像中每个像素的可见性由其深度决定，其强度由它保持可见的时间长度决定。如果静止表面隐藏了移动表面，则曝光时间以及移动表面的强度会降低到 0。否则，如果一个或多个移动表面隐藏了静止表面，则静止表面的强度会降低由在每个模糊图像 $f*h$ 中计算的曝光时间值确定的不可见时间量。如果在给定像素处计算出的运动表面的曝光时间总和超过$T_{frame}$，那么模糊运动表面的强度也会适当降低，并且静止表面当然变得完全不可见。 

# 5. Results

The image sample functions are generated from a 3D scene description by a ray-tracing program previously described in [6,7]. Moving objects are assigned paths from which the motion-blur PSF's are computed. The motion-blur generation, as described in the previous section (Figure 6), has been implemented in both the spatial and frequency domains.

> 图像样本函数是通过先前在 [6,7] 中描述的光线跟踪程序从 3D 场景描述生成的。 运动对象被分配了计算运动模糊 PSF 的路径。 如上一节（图 6）所述，运动模糊生成已在空间域和频域中实现。 

The first example (Figure 7) illustrates the use of multiple PSFs to describe the motions of several objects in a scene. Figure 7(a) shows an instantaneous image of a magnet and ten metallic balls suspended in air. In Figure 7(b) the balls accelerate along their individual paths toward the magnet during an exposure time $T$. In Figure 7(c) the exposure time has been doubled to $2T$ with a corresponding increase in the motion blur. In Figure 7(d) the PSF's of the balls have been modified to simulate a multiple exposure. During the total exposure time $2T$ the shutter was opened five times at $0.4T$ intervals, and each time remained open for $0.2T$. Note in the last three images that the intensity of the moving objects diminishes as the velocity of the objects increases.

> 第一个示例（图 7）说明了使用多个 PSF 来描述场景中多个对象的运动。 图 7(a) 显示了悬浮在空气中的磁铁和十个金属球的瞬时图像。 在图 7(b) 中，在暴露时间 $T$ 期间，球沿着它们各自的路径朝着磁铁加速。 在图 7( c) 中，曝光时间加倍到 $2T$，运动模糊也相应增加。 在图 7(d) 中，球的 PSF 已被修改以模拟多次曝光。 在总曝光时间 $2T$ 期间，快门以 $0.4T$ 的间隔打开五次，每次保持打开 $0.2T$。 请注意，在最后三个图像中，移动物体的强度随着物体速度的增加而减弱。 

**Fig. 7**
![在这里插入图片描述](https://img-blog.csdnimg.cn/f4ff0d9fbf8d490c9ca211e5bd76be27.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/88354157acac4ac595070ad7a6727971.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)


In the second example motion blur is applied to an image containing reflections and refractions of moving objects. The instantaneous image (Figure 8(a)) consists of a cube with an image of a mandrill mapped on its six sides and three transparent spheres. These four objects are reflected in a planar mirror. The finite-exposure image (Figure 8(b)) shows motion blur of the cube and the three spheres as well as their reflections in the mirror. This is accomplished by convolving the motion blur PSF's of an object with all of its image samples (including reflections and refractions) generated by the hidden-surface program.

在第二个示例中，运动模糊应用于包含运动物体反射和折射的图像。 瞬时图像（图 8（a））由一个立方体和三个透明球体组成，其中一个山魈的图像映射在它的六个边上。 这四个物体在平面镜中反射。 有限曝光图像（图 8（b））显示了立方体和三个球体的运动模糊以及它们在镜子中的反射。 这是通过将对象的运动模糊 PSF 与隐藏表面程序生成的所有图像样本（包括反射和折射）进行卷积来实现的。 

**Fig. 8**
![在这里插入图片描述](https://img-blog.csdnimg.cn/1694ec56fc214601a09e0c1cc67bd3c2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center)


# 6. Conclusions

This paper has expanded upon a previously described model of a camera's optical system [6,7] to include motion blur, that is, the ability to integrate image intensity due to moving objects during the time that a camera shutter remains open.

> 本文扩展了先前描述的相机光学系统模型 [6,7] 以包括运动模糊，即在相机快门保持打开状态期间整合由移动物体引起的图像强度的能力。 

The camera model has been described in terms of a generalized image-formation system. This has allowed us to express the motion of objects by a set of optical system-transfer functions which are applied to the points in the image exhibiting the same motion, effectively simulating the camera shutter. In addition, this model allows us to cascade several transfer functions where each transfer function contributes one aspect of the overall camera model.

> 已经根据广义图像形成系统描述了相机模型。 这使我们能够通过一组光学系统传递函数来表达物体的运动，这些函数应用于图像中表现出相同运动的点，有效地模拟了相机快门。 此外，该模型允许我们级联多个传递函数，其中每个传递函数都贡献于整个相机模型的一个方面。 

The implementation of this procedure has been attempted in both the spatial and frequency domains. A general expression for modeling the PSF of an arbitrary motion has been derived. This model has been applied to a 3D scene with multiple objects, each with its own path and velocity description, to generate images simulating motion blur. Examples of uniform blur due to camera motion and blur of reflected and refracted objects have been also presented. The modeling of motion blur in the most general case can become complicated due to object occlusions that may occur during the exposure time.

> 已经在空间域和频域中尝试了该程序的实施。 已推导出用于模拟任意运动的 PSF 的一般表达式。 该模型已应用于具有多个对象的 3D 场景，每个对象都有自己的路径和速度描述，以生成模拟运动模糊的图像。 还介绍了由于相机运动引起的均匀模糊以及反射和折射物体的模糊的示例。 由于在曝光时间期间可能发生的物体遮挡，在最一般情况下运动模糊的建模会变得复杂。 

In this paper we have considered primarily the cam- era effects due to the lens, aperture, and shutter and their use in image synthesis. Future enhancements could be in the area of modeling special-effect filters (star, diffraction), the lens transfer function (optical aberrations) and the noise introduced by the optical system and the imaging medium.

> 在本文中，我们主要考虑了由镜头、光圈和快门引起的相机效果及其在图像合成中的使用。 未来的改进可能是在模拟特殊效果过滤器（星形、衍射）、镜头传递函数（光学像差）以及光学系统和成像介质引入的噪声方面。 

# Glossary

## Symbols

| Symbol             | Description                                                  |
| ------------------ | ------------------------------------------------------------ |
| $e(x, y, z, w)$    | surface representation in $O(x, y, z, w)$                    |
| $f(x', y')$        | image-irradiance function in $O'(x', y')$                    |
| $f(x', y', t)$     | image-irradiance function in $O'(x', y')$ at time $t$        |
| $F(u, v)$          | image-irradiance function in frequency domain                |
| $g(x'', y'')$      | image-output function in $O''(x'', y'')$                     |
| $g(x'', y'', t)$   | image-output function in $O''(x'', y'')$ at time $t$         |
| $G(u, v)$          | image-output function in frequency domain                    |
| $h(x'',y'':x',y')$ | optical transfer function from $O'(x', y')$ to $O''(x'', y'')$ |
| $H(u, v)$          | transfer function $h(x'',y'':x',y')$ in frequency domain     |
| $O(x,y,z,w)$       | 3D object coordinate system                                  |
| $O'(x', y')$       | 2D image-irradiance coordinate system                        |
| $O''(x'',y'')$     | 2D image-output (raster) coordinate system                   |
| $q(x',y':x,y,z,w)$ | geometrical transformation function from $O(x, y, z, w)$ to $O'(x',y')$ |
| $r(t)$             | object path in O(x,y,z,w)                                    |
| $r'(t)$            | projection of path $r(t)$ into $O'(x', y')$                  |
| $t$                | time parameter                                               |
| $T$                | exposure time                                                |
| $\delta(x',y')$    | impulse-reponse function in $O'(x', y')$                     |
| $\triangle x'$     | sampling distance of input function $f(x', y')$ in $x'$      |
| $\triangle x''$    | sampling distance of output function $g(x'', y'')$ in $x''$  |
| $\triangle y'$     | sampling distance of input function $f(x', y')$ in $x'$      |
| $\triangle y''$    | sampling distance of output function $g(x'', y'')$ in $x''$  |

## Abbreviations

| Symbol | Description                                     |
| ------ | ----------------------------------------------- |
| FFT    | fast Fourier transform                          |
| PSF    | point-spread function                           |
| SIPSF  | space-invariant point-spread function           |
| SSIPSF | separable space-invariant point-spread function |
| SSVPSF | separable space-variant point-spread function   |
| SVPSF  | space-variant point-spread function             |

# Acknowledgments

The authors would like to thank Henry Moreton of Sehlumberger-Doll Research for designing the 3D model of the magnet.

# References

[1] Andrews, H. C. and Hunt, B. R., Digital Image Res- toration, Prentice Hall Inc., New Jersey, 1977

[2] Blinn, J. F., "Systems Aspects of Computer Image Synthesis and Animation", SIGGRAPH 1982 Tutorial Notes

[3] Dainty, J. C., and Shaw, R., Image Science, Academic Press, New York, 1974

[4] Goodman, J. W., Introduction to Fourier Optics, McGraw-Hill, Inc., New York, 1968, Chapter 4,5

[5] Newell, M. E., Newell, R. G., and Sancha, T. L., "A New Approach to the Shaded Picture Problem", Proceedings of the ACM National Conference, 1972

[6] Potmesil, M. and Chakravarty, I., "A Lens and Cam- era Model for Synthetic Image Generation", ACM Computer Graphics (Proc. SIGGRAPH 1981), 15, (3), 297-305, August 1981

[7] Potmesil, M. and Chakravarty, I., "Synthetic Image Generation with a Lens and Aperture Camera Model", ACM Transactions on Graphics, 1, (2), 85- 108, April 1982

[8] Pratt, W. K., Digital Image Processing, Wiley- Interscience, New York, 1978

[9] Reynolds, C. W., "Computer Animation with Scripts and Actors", ACM Computer Graphics (Proc. SIG- GRAPH 1982), 16, (3), 289-296, July 1982

[10] Roth, S., "Ray Casting for Modeling Solids", Com- puter Graphics and Image Processing, 18, (1), 109-144, January 1982

[11] Sawchuk, A. A., "Space-Variant Image Motion Degradations and Restorations", Proc. IEEE, 60, (7), 854-861, July 1972

[12] Sawchuk, A. A., "Space-Variant Image Restoration by Coordinate Transformation", JOSA, 64, (2), 138- 144, February 1974

[13] Shack, R. V., "The Influence of Image Motion and Shutter Operation on the Photographic Transfer Function", Applied Optics, 3, (10), 1171-1181, October 1964

[14] Shelley, K. L., and Greenberg, D. P., "Path Specification and Path Coherence", ACM Computer Graphics (Proc. SIGGRAPH 1982), 16, (3), 157- 166, July 1982

[15] Whitted, T., "An Improved Illumination Model for Shaded Display", Comm. ACM, 3, (6), June 1980, 343-349


# 总结

这篇论文其实最关键的就是在第三节推导的公式

$$
h(x, y) = \frac{T}{\sqrt{a_x^2 + a_y^2}}
$$

由于在空间上，上式并不适合以卷积核的形式进行表示，所以可以把运动方向分解为X方向和Y方向两个分量方向，而且可以进一步简化运算为：

$$
h(x) = \frac{1}{a_x} \\
h(y) = \frac{1}{a_y}
$$

只需要依靠控制分母大小就能获得在横向、纵向的模糊；如果需要往某个方向例如 $\vec{Z} = (a_x, a_y)$ 可以根据文论第二章节提到的复杂退化模型的计算方法，即：

$$
g = [[[f \odot h_1] \odot h_2] \odot \cdots \odot h_n]
$$

如果试图让图片中不同的物体向不同的方向执行运动模糊，可以把图像切分为多个区域，每个区域执行不同的退化运算即可（图**Fig. 6** 中提到的计算过程）。这篇文章总体很有意思，也是冈萨雷斯的教科书《数字图像处理》提到图像运动退化时用到的方法，不过原书相关章节内容写的并不是很完美，也缺失一些细节，对于该技术有需要的朋友，这确实是应该仔细研读的一篇好论文。