
![在这里插入图片描述](https://img-blog.csdnimg.cn/584ec3432abb45c188badf58092c1a75.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)



@[toc]

# 一切从列文虎克的显微镜聊起



宗教或者哲学家对于人是怎么产生思考的，曾提出不同的假说。比如赋灵说，感应说等，但无论哪个学派提出哪种假设，都无法从根本上证明或者否定其他学派的思想和观点，于是几方吵吵嚷嚷了数千年，谁也没说服谁，直到1674年，荷兰的科学家列文虎克把血液滴在显微镜下，惊奇的发现那一个个像车轮一样的圆圆的红血球后，从此人类拥有了研究微观世界的能力。



![在这里插入图片描述](https://img-blog.csdnimg.cn/6e4fcd1ef1cd4a39a0776b3ca0437b83.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvaXNvbmNocnk=,size_16,color_FFFFFF,t_70#pic_center)



尽管很快，生物学家借助列文虎克的显微镜很快绘制了很多人体细胞的微观结构，但是那时对于细胞的运作机理，尤其是神经元细胞的运作机理还不甚理解。


![在这里插入图片描述](https://img-blog.csdnimg.cn/e53c6695e786490d8e4fc67dd385220a.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center)
> 1899年，西班牙神经学家圣地亚哥Ramón y Cajal绘制了鸽子小脑的神经元[^1]。

[^1]: https://en.wikipedia.org/wiki/Neuron

时间很快的来到了19世纪，随着研究手段的增加，科学家逐步的理解了神经元细胞的结构和功能；

![在这里插入图片描述](https://img-blog.csdnimg.cn/2a4eb9d91efd432ba6ded45a4c56b0e5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)
它除了一般动物细胞都有基本结构外，还包含其他一些神奇的结构，我们来认识认识：

* 包裹DNA物质，也是神经元最重要核心的——细胞核（Nucleus）
* 包裹线粒体、细胞核等细胞主要结构的——细胞体（Soma）
* 负责接收来自其他神经元细胞放电信号的——树突（Dendrite）
* 负责把电信号传递给其他细胞的——轴突（Axon）
* 以及轴突末端，与其他神经元连接的部分——轴突末端（Nerve Ending）

脑神经科学家们发现，神经元之间依靠带电液，也就是通过神经元细胞身上无数的类似小闸门一样的结构，调整神经元细胞内外之间的电位差。通过释放和吸收钠离子（$Na^+$）氯离子（$Cl^{-}$），钙离子（$Ga^{2+}$），钾离子（ $K^{+}$） 以及阴离子 （$A^{-}$）完成电位差传导电信号。

![在这里插入图片描述](https://img-blog.csdnimg.cn/da901982fa4c487584f90d6dd4e19065.gif#pic_center)
并且，随着研究的深入，科学家们发现神经元传递的电信号，是有时间、脉冲、频率等特征的数字信号。

![在这里插入图片描述](https://img-blog.csdnimg.cn/abb6756f2dd24cf98348ed331edef85c.gif#pic_center)

只不过这个信号和我们已知的数字电路用的电信号有一些不太一样，数字信号大多是PWM波，使用的信号范围通常在 $0～3.3V$ 范围，但是神经元电信号则更多是 $-70mV ~10mV$ 的「尖刺波」。

![在这里插入图片描述](https://img-blog.csdnimg.cn/70f2cd98c5784c128d9ead9741798c2d.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)
另外也观察发现，如果我们持续强化某种刺激后，神经元之间会建立起某种强联系的关系，使得刺激、反馈的时间大大缩短。受神经元的启发，在1943年，神经生物学家 Warren McCulloch 和数学家 Walter Pitts 合作撰写了一篇名为《A logical calculus of the ideas immanent in nervous activity》[^2] 的论文，尝试着用电路模拟了一个功能非常简单的神经网络。

[^2]: 《A logical calculus of the ideas immanent in nervous activity》 https://link.springer.com/article/10.1007/BF02478259

> 这无疑是科学史上的一小步，却是人工智能领域的一大步。---- 打码的某人

在1949年唐纳德·赫布 (Donald Hebb)出版了一本名为《Organization of Behavior》的书，在书中赫布推断了对于神经系统来说，如果进行反复刺激，那么神经元能够更好的记住和使用相关知识，即赫布法则，或者赫布推论。

> 我们可以假定，反射活动的持续与重复会导致神经元稳定性的持久性提升……当神经元A的轴突与神经元B很近并参与了对B的重复持续的兴奋时，这两个神经元或其中一个便会发生某些生长过程或代谢变化，致使A作为能使B兴奋的细胞之一，它的效能增强了。---- 唐纳德·赫布


![在这里插入图片描述å](https://img-blog.csdnimg.cn/54e27ec75c534f5ea4d3aa74460c94a5.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvaXNvbmNocnk=,size_16,color_FFFFFF,t_70#pic_center)

# 人工智能的春天

尽管受限于当时的观察手段和技术的落后，脑神经科学的领域发展缓慢，但是在计算机领域却随着算力的逐步提升，1950年，人工智能迎来了发展的原点。在IBM研究实验室的 Nathanial Rochester  率先尝试模拟神经元网络的结构，尽管当时的尝试失败了，却在不久之后实验成功了。

而同一时间，大洋彼岸的英国。一位怪才发表了一篇注定震惊世界，并且在其死后依然长期影响深远的论文《COMPUTING MACHINERY AND INTELLIGENCE》[^3]。

这位科学怪才就是图灵，并且为了纪念他对科学的重大贡献，后人们把评判计算机是否具有智能的测试命名为 **「图灵测试」**。

[^3]: https://link.springer.com/chapter/10.1007%2F978-1-4020-6710-5_3

> 如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。 ---- 阿兰·图灵。

![在这里插入图片描述](https://img-blog.csdnimg.cn/6310c91ae09249ea975efc43570c8496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvaXNvbmNocnk=,size_16,color_FFFFFF,t_70#pic_center)

当时这篇文章发表后并未引起多少轰动，根本的原因是由于算力与理论方面的制约不足以产生能够影响世界的人工智能，而且为了达成一定的计算能力需要消耗巨大的资源，且在那个时候开始处理一般任务的传统计算开始兴起，所以 IBM 在 Nathanial Rochester 的实验尽管成功之后，也并未持续投入足够多的资源支持他的研究。

## 1956年——达特茅斯会议

希望和曙光就在那，创造人工智能的强烈愿望并未能阻挡科学家的脚步。在1956年夏季的达特茅斯学院，一群科学怪人聚在了一起，从左往右这些人分别是：

* 约翰·麦卡锡（John McCarthy，1927年9月4日－2011年10月24日），生于美国马萨诸塞州波士顿，计算机科学家。他因在人工智能领域的贡献而在1971年获得图灵奖。实际上，正是他在1956年的达特矛斯会议上提出了“人工智能”这个概念[^4]。
* 马文·李·明斯基（Marvin Lee Minsky，1927年8月9日－2016年1月24日），生于美国纽约州纽约市，美国科学家，专长于认知科学与人工智能领域，麻省理工学院人工智能实验室的创始人之一，著有几部人工智能和哲学方面的作品。1969年，因为在人工智能领域的贡献，获得图灵奖[^5]。
* 克劳德·艾尔伍德·香农（Claude Elwood Shannon，1916年4月30日－2001年2月24日），美国数学家、电子工程师和密码学家，被誉为信息论的创始人。香农是密歇根大学学士，麻省理工学院博士[^6]。
* 雷·所罗门诺夫(Ray Solomonoff，July 25, 1926 - Dec 7, 2009)，算法概率的发明者和归纳推理的一般理论算法信息论之父。
* 艾伦·纽厄尔（Allen Newell，1927年3月19日－1992年7月19日）是计算机科学和认知信息学领域的科学家，曾在兰德公司，卡内基梅隆大学的计算机学院、泰珀商学院和心理学系任职和教研。他是信息处理语言（IPL）发明者之一，并写了该语言最早的两个AI程序，合作开发了逻辑理论家（Logic Theorist 1956年）和一般问题解决器General Problem Solver。1975年他和赫伯特·西蒙（司马贺）一起因人工智能方面的基础贡献而被授予图灵奖[^7]。
* 赫伯特·亚历山大·赛门（Herbert Alexander Simon，1916年6月15日－2001年2月9日），汉名为司马贺，美国著名学者、计算机科学家和心理学家，研究领域涉及认知心理学、计算机科学、公共行政、经济学、管理学和科学哲学等多个方向。1975年图灵奖得主，1978年，获得诺贝尔经济学奖[^8]。
* 阿瑟·李·塞缪尔(Arthur L. Samuel) 作为人工智能研究的先驱（以其玩冠军级别跳棋的程序而闻名）[^9]。
* 奥利弗·戈登·塞尔弗里奇 （Oliver Gordon Selfridge, 1926 年 5 月 10 日 - 2008 年 12 月 3 日）是人工智能的先驱。 他被称为“机器感知之父”。
* 纳撒尼尔·罗切斯特（英语：Nathaniel Rochester，1919年1月14日－2001年6月8日），是IBM 701总设计师，编写了第一个汇编语言，并参与了人工智能领域的创立[^11]。
* Trenchard More 是一位退休的数学家和计算机科学家，曾在麻省理工学院和耶鲁大学任教后，曾在 IBM 的 Thomas J. Watson 研究中心和剑桥科学中心工作。

[^4]: https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1
[^5]: https://zh.wikipedia.org/wiki/%E9%A9%AC%E6%96%87%C2%B7%E9%97%B5%E6%96%AF%E5%9F%BA
[^6]: http://raysolomonoff.com/
[^7]: https://zh.wikipedia.org/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94
[^8]: https://zh.wikipedia.org/wiki/%E5%8F%B8%E9%A9%AC%E8%B4%BA
[^9]: https://history.computer.org/pioneers/samuel.html
[^11]: https://zh.wikipedia.org/wiki/%E7%BA%B3%E6%92%92%E5%B0%BC%E5%B0%94%C2%B7%E7%BD%97%E5%88%87%E6%96%AF%E7%89%B9



![在这里插入图片描述](https://img-blog.csdnimg.cn/aa266a1f010848b2b6f9522a0cca22ab.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

在大会上，大佬们围在一起讨论着这么几个问题：

* 大脑是如何工作的？
* 我们能否设计一个机器来模拟大脑？

尽管在达特茅斯会议上，对这些问题没能达成一致意见。但是在之后出版的会刊上， Artificial Intelligence 这个名字被赋予了这一新兴学科，并且在很大程度上促进了学界对AI的研究。甚至在一定程度上，因为科学家对算力的需求，促成了早期计算机的发展。

在达特茅斯计划之后的几年里，约翰·冯·诺依曼建议通过使用电报继电器或真空管来模仿简单的神经元功能。此外，康奈尔大学的神经生物学家，也是成就足以匹敌图灵，但是却不如他有名的 **弗兰克·罗森布拉特 (Frank Rosenblatt)** 在1950 年代初期率先提出了 **「感知机」** 的概念。

> 创造具有人类特质的机器，一直是科幻小说里一个令人着迷的领域。但我们即将在现实中见证这种机器的诞生，这种机器不依赖人类的训练和控制，就能感知、识别和辨认出周边环境。----弗兰克·罗森布拉特

![在这里插入图片描述](https://img-blog.csdnimg.cn/b7df5c479cee4d64853f77d556251c6b.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)
> 《智能自动机的设计》（The Design of an Intelligent Automaton）的第一页，文章于1958年夏季在康奈尔航空实验室的《研究趋势》（Research Trends）上发表。

罗森布拉特发现单层感知器可用于将一组连续值的输入分类为两个类别之一。感知器计算输入的加权总和，减去阈值，然后将两个可能值之一作为结果传递出去。不幸的是，感知器是有限的，并且在 Marvin Minsky 和 Seymour Papert 1969 年出版的 「感知器」一书中的「幻灭年」中证明了这一点。

屋漏偏逢连夜雨，1966年机器翻译的失败，之后不久的1970年，联结主义的放弃；给当时的怀疑论者提供了口实，其中一个理由就是「花了那么多钱，结果却做出来一堆破铜烂铁」。

从那个时候开始，要求削减经费，甚至取消这个学科的风声渐渐影响了当时推动学科发展的各大金主们。

# 人工智能的第一个冬天

随着技术的发展，导致当时的人们夸大了神经网络的潜力，并且限于当时电子技术的局限性，这种过度的炒作，尤其是来自文学电影的渲染，给当时的公众带来了莫名的恐惧。加之工业对于新技术期望的落空，多方原因下使得人工神经网络的发展遭受巨大的打击，最终政府部门、以及企业纷纷暂停或削减了对这方面的资金支持。

时间来到1974年，AI 的发展经历了自1956年以来的重大挫折，从那一年开始，一直到1980整整6年的行业寒冬期。在此期间还伴随着如同 N1 火箭爆炸那样的事件，沉重的打击了整个 AI 行业。

* 1971 - 1975年：美国国防高等研究计划署在卡内基美隆大学所进行的语音辨识研究遭到挫折。
* 1973年：英国的人工智研究受到莱特希尔对国会的报告所影响而大幅减少。
* 1973 - 1974年：美国国防高等研究计划署削减对人工智能的学术研究。

当时的人们发现例如逻辑证明器、感知器、增强学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。这当然还有很重要的一点，就是跟今天的半导体技术相比实在处理性能实在过于羸弱。

而在在神经网络这项技术提出前，当时也没人能够理解如何让程序理解和处理丰富的信息，并且随着问题的深入，需要处理的变量呈现指数级的增长，对于当时寸K寸金的硬件，还是科学家来说，实在超出了理解范围。

例如，神经网络出现前，即便对数学家来说想要在短期内求解极复杂的微积分问题，而且不出错是几乎不可能的。而且限制当时 AI 技术发展除了以上的原因外，还有另外一个很容易被人忽略的问题，就是以当时的技术条件，想设计一个 AI 需要的巨大数据量的数据库是不可能的。

所以 AI 在1974年至1980年这6年，几乎沉寂下去，相关实验室也招不到愿意从事这方面研究的研究员，而且曾从事这个领域的科学家们为了经费，也纷纷转变了自己的研究方向。

# 人工智能的第二个冬天

80年代初，基于「决策树」而提出的「专家系统」重新走进公众的目光，由于它基于引索和经验，且设计方式十分简单，所以自提出后，尤其是医药公司成为了这类技术的背后主推者。

例如，在看病时，医生可以通过向「专家系统」输入病患的特征，可以快速的在知识库中检索到最有效果治疗方案，并作为看诊医生的备选方案。这也是自诞生到现在，依然在广泛使用的 AI 系统。

但是这类系统有很大的局限性，正如上面提到的看诊，「专家系统」只能针对特定的行业，并且极其依赖已有的先验知识。所以知识库建立的不完善，以及扩展迁移都会带来巨大的成本，这对于一些经常发生变化的系统来说，维护成本高昂。所以经过大约6-7年的发展后，AI 又一次迎来了冬天。

所以对于AI来说，有据可查的冬天有两个：

* 1974年 至 1980年的第一次寒冬
* 1987年 至 1993年的第二次寒冬

以及几个小低潮：

1987年：Lisp机器市场的萎缩。
1988年：国家战略计算计划取消对AI研究的新花费。
1993年：专家系统逐渐达到极限。

# 人工神经网络（Artificial Neural Network）与 AI 大爆发的这二十年
AI 技术能在这些年蓬勃发展，离不开 AI 寒冬期仍然坚持的学者。1989年，扬·勒丘恩（Yann LeCun）[^10]等人在1974年提出的标准反向传播算法首次应用于深度神经网络[^11]，并用于处理手写邮政编码的识别。这也是现在研究生阶段初学机器学习的学生要做的第一个小课程作业。当时的工作进展并不顺利，存在许多问题，例如直到1991年赛普·霍克赖特于1991年[^12]提出的梯度消失问题。

[^10]:  https://baike.baidu.com/item/%E6%9D%A8%E7%AB%8B%E6%98%86/51137221
[^11]: P. Werbos., "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences," PhD thesis, Harvard University, 1974.
[^12]: S. Hochreiter., "Untersuchungen zu dynamischen neuronalen Netzen," Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber, 1991.

此外随着1993年后，随着芯片制程工艺[^13][^14] 技术的进步，尤其是以 Intel 奔腾处理器为代表的新一代 x86 架构的高性能CPU的问世，为 AI 的发展提供了从实验室走向应用的可能。

[^13]: https://wiki.mbalib.com/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B
[^14]: https://baike.baidu.com/item/%E5%A5%94%E8%85%BE%E5%A4%84%E7%90%86%E5%99%A8/673315

于是以 ANN、反向传播为代表的新一代AI技术 —— 深度学习，重新激发了科学家的兴趣，并在ANN的基础上，提出了其改进型的例如CNN，RNN等网络模型，预测精度也随之逐渐提高。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2bc509380f6f4c2eb79691d002baa6a9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center)
在这期间有两个代表性事件

## ImageNet

提到近二十年AI的发展，不得不提到一个华人科学家——李飞飞的名字。李飞飞等人在2009年发表了一篇题为《ImageNet: A Large-Scale Hierarchical Image Database》的论文，并制作了一个囊括2.2万类，即便是现在也是包含数据最多之一的数据库，并且随同数据一同提出的还有5个问题：

*  图像分类问题
* 目标定位问题
* 目标检测问题
* 视频目标检测问题
* 场景分类问题

于是以 ILSVRC-ImageNet 为名的全球计算机视觉竞赛开始了。她从2010开始，到2017年结束。从最初的识别率不到一半，到最后错误率仅2%左右。

## AlphaGo 

![在这里插入图片描述](https://img-blog.csdnimg.cn/aca8f874311a4413b0f230bd5b711b8f.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)
AlphaGo以前，在人类智力挑战中已经有深蓝击败了当时的国际象棋冠军的故事。而在AlphaGo以前，人类普遍认为对于运算量是天文数字的围棋，人工智能可能仍热不能胜任这样的任务。于是在2016年3月，由谷歌DeepMind研发的AlphaGo在围棋人机大战中击败韩国职业九段棋手李世乭。随后，大众开始熟知人工智能，各个领域的热情都被调动起来了。

至此，AI应用如同雨后春笋般涌现，并在方方面面地影响着我们的生活。例如自动巡航、路径规划、偏好推送、文字语音翻译等。但是，你要问我们能否已经迎来了AI时代吗，我认为并非如此。


# 目前的AI能做什么

目前我们使用AI技术，最主要的应用方向在四大类，其中之一时自然语言处理（NLP：Nature Language Processing），它包含语音识别、声音识别、语义分析、文本分析等；

而对于数字图像处理（Digial Image Processing），包含人脸检测、人体体态识别、物体识别、运动识别、图像分离等，最近这几年随着AI的兴起和技术积累，沉积多年的计算机图形技术也重新焕发生机，出现一些虚拟仿真等；

此外由于医疗一直是推动图像学技术的主要需求，随着AI技术的引入，对于医疗中的疾病预测、建模、图像增强等方面也有了较大的发展，这里比较有代表性的就是18年开始的脑机接口方向；

然后就是与传统机械结合而在最近十年有了长足发展的机器人技术，比如用来举例已经烂大街的波士顿动力；机器人运动的姿态平衡，路径规划等问题，在以前使用机器学习的相关技术调整PID等，存在很多技术难点，而使用了AI技术后也都有了不错的表现。

有的文献可能会提到大数据，但是随着04年中国电商的发展，而快速成熟的大数据技术，其底层建立在分布式系统之上，在分布式的硬件基础上又增加了异步的文本分析、数据查询存储等SaaS服务，例如目前在很多中型团队（100人左右规模），使用的技术如Haddop，Hive，NoSQL等。即便实现了号称所谓的用户画像、精准推送，异常分析等，但在我看来更多的是应用到了统计范畴的数据挖掘技术，比如说聚类分析，甚至可能只是简单的 if-else 型的条件决策树（表），而很少有能过称得上AI的技术应用。

![在这里插入图片描述](https://img-blog.csdnimg.cn/78f0eaa6be5c49818d58c838751a5637.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvaXNvbmNocnk=,size_16,color_FFFFFF,t_70#pic_center)
AI (Artificial Intelligence) 如果我没记错的话，也是这十年左右才开始为公众所熟知并且正式成为一个概念的。甚至对于一些师资力量比较薄弱的高校和科研院所，甚至没有对于AI的准确认知。

当然现在不一样了，连做嵌入式方向的老师也经常谈论AI。这虽然是好事，但是跟之前的时代相似，现在很多人对这个技术的期望有点超过了当前它所能达到的极限。


# 参考资料

* 「History of Neural Networks」，http://www2.psych.utoronto.ca/users/reingold/courses/ai/cache/neural4.html
* 「人工智能简史系列推送（1）：“华山论剑”——达特茅斯会议」，TABS创新实验室，https://zhuanlan.zhihu.com/p/196754544
* 「人工智能，请准备迎接冬天」 ，欧小刚，https://www.sohu.com/a/163650584_434604
* 「天文史上的今天 | 人类历史上最猛烈的火箭爆炸事故」，shn117，https://zhuanlan.zhihu.com/p/39026467
* Nicolas-Alonso LF, Gomez-Gil J. Brain computer interfaces, a review. Sensors (Basel). 2012;12(2):1211-1279. doi:10.3390/s120201211
* J. Deng, W. Dong, R. Socher, L. Li, Kai Li and Li Fei-Fei, "ImageNet: A large-scale hierarchical image database," 2009 IEEE Conference on Computer Vision and Pattern Recognition, 2009, pp. 248-255, doi: 10.1109/CVPR.2009.5206848.
* 「ImageNet这八年：李飞飞和她改变的AI世界」，量子位，https://zhuanlan.zhihu.com/p/28142670