@[toc]

# 提出问题
已知如下图形在[0，10]区间内呈现高斯分布特征，在已知高斯公式表达式为：

$$
p(z) = \frac{1}{ \sqrt {2 \pi } \sigma } e^(- \frac{(z- \mu )^2}{2 \sigma^2} )
$$

时，且已知图像中每一点坐标的X Y值，如何求解标准差 $\sigma$ 以及期望 $\mu$？

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210504181721127.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvaXNvbmNocnk=,size_16,color_FFFFFF,t_70#pic_center)

# 暴力求解

针对这样一个问题，在没有学过梯度下降之前，我们能想到的就是给可能出现的标准差 $\sigma$ 以及期望 $\mu$ 列一张表，然后分别带入高斯公式中，然后进行比较。

想法虽然没有错，但由于标准差 $\sigma$ 以及期望 $\mu$ 存在着多种可能性，而且各是一个待解的参数，每一个参数各是一维，所以这个问题很容易变成 $O(n^2)$。对于高维问题，这个问题很容易就变成了 $O(n^m)$ 的计算量。如果问题需要计算的参数相对有限，且待处理的变量是有限个数，那么使用暴力求解，也是可以的。

而为了减少这样的计算量，使得问题可以在有限空间内找到最优解，我们需要换一个思路来处理这个问题。

# 评价函数
评价函数是一个非常重要的概念。假设我们已经找到了几个可能是解的 $\sigma$ 以及$\mu$ ，我们怎么知道谁比谁更好？例如对于如下这张表：

$\mu$ | $\sigma$ 
---------|------------
5.5 | 1.2
6.1 | 0.3
4.7 | 0.8
4.5 | 1.1

我们怎么知道这些解谁比谁更好，以及如果以上解都不满意的时候，我们怎么知道需要的解在哪个范围内，以及如何进一步去逼近呢？

所以我们要有个评价函数去帮助我们判断这个结果，那么一个最简单的方式，就是计算求解后的$\mu$ 和 $\sigma$ 得到的新的函数值与待解函数值之间的方差：

$$
z = (y - y_o) ^ 2
$$

这是一个点的，如果我们要得到一个关于整体的评价结果，就可以这样做

$$
Z = \sum (y - y_o) ^ 2
$$

把每一点的方差都加和起来，看看这个Z的值谁更小一点，也就是说当Z越趋近于0时，我们得到的结果越接近于真实的曲线数据，当然，如果等于0那是最好的。

# 梯度曲线

梯度下降之所以叫梯度下降，是因为这里涉及到了梯度曲线，那这梯度曲线怎么来的呢？我们回头看一眼这个评价函数。

$$
Z = \sum (y - y_o) ^ 2
$$

再回想一下导数的定义是什么：

$$
\frac{dy}{dx} = \frac{f(x + \Delta x) - f(x)}{\Delta x}
$$

通常这里的$\Delta x$是一个大于0，但又是无限接近于0的数。如果函数是一个单调递增的函数，那么我们必然会有$f(x + \Delta x) > f(x)$，此时如果朝着函数值递增方向求解，会有无穷的解而无法收敛。所以此时我们需要换个方向，朝着函数的最小值去获得最优解。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210703200613145.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvaXNvbmNocnk=,size_16,color_FFFFFF,t_70#pic_center)

所以，你发现了吗，这里的梯度下降，就是这个意思。用比较数学的语言解释，就是求导数的过程，如果我们把计算过程中的导数绘制成新的线图来观察，大概就是这样的，这就是梯度下降算法的实际数学含义。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210504194501590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvaXNvbmNocnk=,size_16,color_FFFFFF,t_70#pic_center)
当我们找到gredient图中最小值的时候，也就意味着我们找到了最优解，当然这个最优解可能是全局最优也有可能是局部最优。

# 学习率
为了逼近原函数，我们必须每次十分小心的修改参数的值，这一过程有时被描述为学习率，有的地方又称为步进。由于我们不可能一次性找到最佳参数，所以只能逐次的进行比较。由于程序是一个循环过程，所以我们需要确定步进的大小，如果用流程图描述全部过程，大概就是这样的：

```mermaid
flowchat
st=>start: 开始：随机输入参数
e=>end: 结束：输出参数
op1=>operation: 结果评价
op2=>operation: 更新参数
cond=>condition: 是否最优解？

st->op1->cond
cond(yes)->e
cond(no)->op2->op1
```

学习率如果过大，程序有可能会跳过最优解，而无法收敛；如果过小，有可能会陷入局部最优解，而无法找到全局最优解。所以这个是设计者需要仔细考虑的地方。在下一章节里，我们将实现一个简单的梯度下降算法。

🍀祝你好运



