@[toc]


# 什么是「有监督学习（Supervised Learning）」
所谓「有监督学习」，指的是使用既有 **「特征 $x$」** 又有 **「标签 $y$」** 的数据，

$$
f(x) = \omega x + b
$$

我们通过模型输入 $x$，得到预测输出 $\hat y$，然后通过比较标签 $y$ 和 $\hat y$ 的差异情况，来调节模型的权重 $\omega$，最终使模型达到或趋近观测情况的建模过程。

常见的「有监督学习」的机器学习方法如下：

* 支持向量机（Support Vector Machines）
* 神经网络算法（Neural network algorithm）
* 线性回归（linear regression）
* 逻辑回归（logistic regression）
* 朴素贝叶斯（naive Bayes）
* 线性判别分析（linear discriminant analysis）
* 决策树（decision trees）
* K-近邻（k-nearest neighbor algorithm）

## 「有监督学习」任务的缺点
因为要求训练数据都是有标注的，而数据标注成本往往十分巨大，这是因为基本上数据标注都是人手工标注，数据标注花费的人力、物力、财力不是普通组织和个人所能承担。这导致对于大多数公司、个人、学校甚至研究机构来说，可应用范围受限，从事「机器学习」方面的组织和个人，于是只能通过仅有的开源数据集调试、训练自己的模型。

# 什么是「无监督学习（Unsupervised Learning）」
无监督学习，我们并不是很幸运的能在任何场景下都能获得一组 **「特征 $x$」** 和 **「标签 $y$」**，如果得到的数据 $x$ 本身有一定的客观规律或特性，我们可以 **通过分析数据本身的客观规律，通过统计学的方法，找出适用的模型**。

常见的「无监督学习」的机器学习方法如下：
* 聚类
* 主成分分析方法（PCA）
* 密度估计（Density Estimation）
* 异常检测（Anomaly Detection）

## 「无监督学习」任务的缺点

**真实生活中，绝大部份数据都是无标注数据，对无标注数据的研究，也是未来AI方向的重点**。但是正因为缺少了必要的标注，导致很多在「有监督学习」中表现良好的工具，无法在没有数据标注的场景下发挥使用。

另一方面，现有的「无监督学习」工具能够处理的任务十分简单，复杂环境下比如「信噪比」偏低，或者数据特征不明显的，几乎无法使用。尽管「无监督学习」才是未来AI的主流，但是发展困难重重。在当下企业的应用中，「无监督学习」大多只使用到类似「聚类」技术，并且仅用在了传统的安全和行为检测上。

# 什么是「半监督学习（Semi-supervised Learning）」
为了能够处理「有监督学习」工具无法应用在「无监督学习」场景的问题，有一部分科学家提出对无标注数据进行部分标注，而提出了「半监督学习」的概念。

对于半监督学习，其训练数据的一部分是有标签的，另一部分没有标签，而没标签数据的数量常常极大于有标签数据数量（这也是符合现实情况的）。

**我们从统计学的经验出发，于已标注数据相关的数据，必然是不完全随机的，于是我们可以数据的分布情况，从而揭示或得到一个可接受的分类结果。**

比如说我们训练模型，让模型能够识别出猫的照片，我们可以人工标注数百张猫的图片后，先给机器进行训练，得到一个粗糙的结果。之后再喂给模型数千没有标注的，但是有猫的图片让模型从数据中总结出一个统计学性质的特征信息。

通常，「半监督学习」涉及的知识分为可以按照树图描述如下

![在这里插入图片描述](https://img-blog.csdnimg.cn/9dd987ec70834dd787c8edda3ee2228a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omT56CB55qE6Zi_6YCa,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

## 「半监督学习」任务的缺点
「半监督学习」能够较好的适应大多数的任务，少部分情况下能够对抗噪音复杂的环境，同时它也是当下AI技术研究的主流，它不仅克服了「有监督学习」需要昂贵的数据标注，也比单纯的「无监督学习」能适用于更多的场景。

但正如「不可能三角」理论那样，不可能同时满足使用者所有的需求一样。它算是AI技术中，最难掌握，而且特别依赖个人长期经验和技巧的技术，所以在当下能够掌握这方面技术的人其实很少。